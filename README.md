# barcode-detection

–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–æ–Ω ‚Äì –≥—Ä—É–±—ã–µ –∫–æ—Ä–æ–±–∫–∏ (bbox detection). –ò—â–µ–º –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–µ –∏ –¥–≤—É–º–µ—Ä–Ω—ã–µ –∫–æ–¥—ã –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö: qr, ean13, ean8, upc, 1d (–Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–º–µ—Ä–∫–∏), dm, az, pdf, id (–Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å), hd (—Ç—Ä—É–¥–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å).

# –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏

–í –¥–∞–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ —è —Ä–µ—à–∞—é –∑–∞–¥–∞—á—É –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, —à—Ç—Ä–∏—Ö-–∫–æ–¥–æ–≤ —Ç–∏–ø–∞ ean13) –∏ –¥–≤—É–º–µ—Ä–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, qr-–∫–æ–¥—ã) –∫–æ–¥–æ–≤ –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö. –ú–æ—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã–¥–∞—ë—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —á–µ—Ç—ã—Ä–µ—Ö —É–≥–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∏–≥—É—Ä—ã, –≤ –∫–æ—Ç–æ—Ä—É—é –ø–æ–º–µ—â–∞–µ—Ç—Å—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–¥, –∏–ª–∏ —Å–æ–æ–±—â–∞–µ—Ç –æ–± –µ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏. 

__Input:__ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .jpg –∏–ª–∏ .png ‚Äì —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —Å –º–æ–±–∏–ª—å–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–¥–æ 5 –ú–±)

__Output:__ –º–∞—Å—Å–∏–≤ –≤–∏–¥–∞ [(ùë•1, ùë•2, ùë•3, ùë•4), ...] ‚Äì –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã left top ‚Äì right bottom —É–≥–ª–æ–≤ bbox‚Äô–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∫–æ–¥. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ —à—Ç—Ä–∏—Ö–∫–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ï—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥ –∫–∞—Ä—Ç–∏–Ω–∫—É —Å bbox‚Äô–æ–º.

## –ú–µ—Ç—Ä–∏–∫–∏

–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ - mAP (mean Average Precision), IoU (Intersection over Union), Hausdorff Distance, Precision, Recall, F1-score.

## –í–∞–ª–∏–¥–∞—Ü–∏—è

–î–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–æ—Ä–æ–∫ –∏—Å–ø–æ–ª—å–∑—É—é –º–µ—Ç–æ–¥ K-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é —Å 5 —Ñ–æ–ª–¥.

## –î–∞–Ω–Ω—ã–µ 

–ú–æ–π –¥–∞—Ç–∞—Å–µ—Ç: 117 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π 1D –∏ 2D –∫–æ–¥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .jpg –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º —Ñ–∞–π–ª—ã .json (–∏–º—è-—Ñ–æ—Ç–æ.jpg.json) —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π. –ò–∑ –Ω–∏—Ö:
```
qr  | ean13 | 1d | dm | pdf | upc |  hd | id |

103 |   83  | 69 | 69 |  4  |  3  | 159 | 68 |
```
# –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

__–ë–µ–π–∑–ª–∞–π–Ω__

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª—å—é YOLO (–±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è)

__–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å__

yolov5s.pt

__–í–Ω–µ–¥—Ä–µ–Ω–∏–µ__

–ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –ø–∞–∫–µ—Ç —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥—É–ª–µ–π, –æ—Ç–≤–µ—á–∞—é—â–∏—Ö –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é, –∞ —Ç–∞–∫–∂–µ –∑–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏

# Setup
## Prerequisites
1. Python 3.9 or higher

2. Git

3. Poetry (for dependency management)

## Installation
1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:

```
git clone <your-repository-url>
cd barcode-detection
```
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Poetry (–µ—Å–ª–∏ –µ—â—ë –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ):
```
curl -sSL https://install.python-poetry.org | python3 -
```

3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ dependencies:
```
poetry install
```

4. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ virtual environment:

```
poetry shell
```

5. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pre-commit —Ö—É–∫–∏:

```
pre-commit install
```

6. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ setup:

```
pre-commit run --all-files
```

7. Data Setup
–¢–∞–∫ –∫–∞–∫ –¥–∞—Ç–∞—Å–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—Å—è –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –µ—Å—Ç—å —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:

```
data/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ image1.json
‚îÇ   ‚îú‚îÄ‚îÄ image2.jpg
‚îÇ   ‚îú‚îÄ‚îÄ image2.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ image1.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ image1.jpg
    ‚îú‚îÄ‚îÄ image1.json
    ‚îî‚îÄ‚îÄ ...
```

8. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ DVC for data versioning:

```
dvc init
dvc add data/train data/val data/test
git add data.dvc .dvc/config
git commit -m "Add data with DVC"
```

9. MLflow Setup
Start MLflow server for experiment tracking:

```
mlflow server --host 127.0.0.1 --port 8080
```
The MLflow UI will be available at http://127.0.0.1:8080

## Train
1. –° –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:

```
python commands.py train
```

2. –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
–ú–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```
python commands.py train training.epochs=100 training.dataloader.batch_size=32 model.model_size=m
```

3. Training Steps
Data Loading: –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ configured directories

## Model Initialization: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç YOLO —Å pretrained weights

1. Training Loop: Trains the model with PyTorch Lightning

2. Validation: Validates on validation set each epoch

3. Checkpointing: Saves best models based on validation mAP

4. Logging: Logs metrics, parameters, and artifacts to MLflow

## Training Monitoring
1. MLflow UI: –°–º–æ—Ç—Ä–∏—Ç–µ training metrics, –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –Ω–∞ http://127.0.0.1:8080

2. TensorBoard logs: Automatically logged by PyTorch Lightning

3. Console output: Real-time training progress

4. Plots directory: Training plots saved to plots/ directory

## Configuration Files
Training behavior is controlled by YAML configuration files in configs/:

1. config.yaml - Main configuration

2. data/local.yaml - Data loading configuration

3. model/yolo.yaml - Model architecture configuration

4. training/default.yaml - Training hyperparameters

5. mlflow/default.yaml - MLflow logging configuration

## Production Preparation
Model Conversion to ONNX
1. Convert the trained PyTorch model to ONNX format for deployment:

```
python commands.py convert_onnx outputs/best.pt outputs/model.onnx
```
2. Model Conversion to TensorRT
3. Convert ONNX model to TensorRT for optimized GPU inference:

```
python commands.py convert_tensorrt outputs/model.onnx outputs/model.trt --precision fp16
```

## Production Artifacts
After training and conversion, the following artifacts are ready for production deployment:

1. outputs/best.pt - Best PyTorch model checkpoint

2. outputs/model.onnx - ONNX model for cross-platform deployment

3. outputs/model.trt - TensorRT engine for optimized GPU inference

4. configs/ - Configuration files needed for inference

5. plots/ - Training visualizations and metrics

## Deployment Requirements
–î–ª—è production deployment –≤–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è:

1. PyTorch or ONNX Runtime (depending on model format)

2. OpenCV for image preprocessing

3. NumPy for numerical operations

4. FastAPI (for REST API server)

## Minimal inference dependencies:

```
pip install torch onnxruntime opencv-python numpy fastapi uvicorn
```

## Infer
Input Data Format
–°–æ–∑–¥–∞—ë—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö (JPEG, JPG, PNG). –î–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ –∫–∞–∂–¥–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–π—â—É—é —Ä–∞–∑–º–µ—Ç–∫—É .json —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:

```
json
{
  "objects": [
    {
      "data": [
        [x1, y1],
        [x2, y2], 
        [x3, y3],
        [x4, y4]
      ],
      "class": "qr"
    }
  ]
}
```

Single Image Inference

```
python commands.py infer path/to/image.jpg results/predictions.json
```

Batch Inference
```
python commands.py infer path/to/images/ results/batch_predictions/
```
Using ONNX Model
```
python commands.py infer path/to/image.jpg results/predictions.json --model_path outputs/model.onnx
```
Inference Server
Start a REST API server for real-time inference:

```
python commands.py serve --model_path outputs/best.pt --host 0.0.0.0 --port 8080
```

The server provides the following endpoints:

1. POST /predict - Upload image for detection

2. GET /health - Health check endpoint

3. GET /info - Model information

## –ü—Ä–∏–º–µ—Ä API usage:

```
curl -X POST "http://localhost:8080/predict" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@path/to/image.jpg"
```
Output Format
Inference results are returned in JSON format:

```
json
{
  "detections": [
    {
      "bbox": [x1, y1, x2, y2],
      "confidence": 0.95,
      "class": "qr",
      "corners": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    }
  ],
  "image_shape": [height, width],
  "processing_time": 0.123
}
```

## Model Evaluation
–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

```
python commands.py evaluate --model_path outputs/best.pt --data_split test
```

## Project Structure
```
barcode-detection/
‚îú‚îÄ‚îÄ configs/                    # Hydra configuration files
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml            # Main configuration
‚îÇ   ‚îú‚îÄ‚îÄ data/                  # Data configurations
‚îÇ   ‚îú‚îÄ‚îÄ model/                 # Model configurations
‚îÇ   ‚îú‚îÄ‚îÄ training/              # Training configurations
‚îÇ   ‚îú‚îÄ‚îÄ inference/             # Inference configurations
‚îÇ   ‚îî‚îÄ‚îÄ mlflow/                # MLflow configurations
‚îú‚îÄ‚îÄ barcode_detection/         # Main Python package
‚îÇ   ‚îú‚îÄ‚îÄ data/                  # Data loading modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_module.py     # PyTorch Lightning DataModule
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py         # Dataset class
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transforms.py      # Data augmentation
‚îÇ   ‚îú‚îÄ‚îÄ models/                # Model definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo_lightning.py  # PyTorch Lightning YOLO wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py         # Evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ training/              # Training utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trainer.py         # Training logic
‚îÇ   ‚îú‚îÄ‚îÄ inference/             # Inference utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.py       # Model inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.py          # FastAPI server
‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Utility functions
‚îÇ       ‚îú‚îÄ‚îÄ logging.py         # Logging setup
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py         # Helper functions
‚îú‚îÄ‚îÄ data/                      # Data directory (not in git)
‚îú‚îÄ‚îÄ outputs/                   # Model outputs
‚îú‚îÄ‚îÄ plots/                     # Training plots
‚îú‚îÄ‚îÄ logs/                      # Log files
‚îú‚îÄ‚îÄ commands.py                # Main CLI entry point
‚îú‚îÄ‚îÄ convert_to_production.py   # Model conversion script
‚îú‚îÄ‚îÄ pyproject.toml            # Poetry dependencies
‚îú‚îÄ‚îÄ .pre-commit-config.yaml   # Pre-commit hooks
‚îî‚îÄ‚îÄ README.md                 # This file
```

## Development
Code Quality
–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –≤ –ø—Ä–æ–µ–∫—Ç–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è:

1. Black: Code formatting

2. isort: Import sorting

3. flake8: Linting

4. pre-commit: Git hooks for quality checks

## –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤—Ä—É—á–Ω—É—é:

```
pre-commit run --all-files
```
–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
–î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å Poetry:

```
poetry add package_name
```
For development dependencies:

```
poetry add --group dev package_name
```

Configuration Management
–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Hydra –¥–ª—è configuration management. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —è–≤–ª—è—é—Ç—Å—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º–∏ –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã:

```
python commands.py train model=yolo training=custom data=local
```

Data Versioning
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é DVC. –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö:

```
dvc add data/new_dataset
git add data/new_dataset.dvc
git commit -m "Add new dataset"
```

## Experiment Tracking
–í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é MLflow:

1. Hyperparameters

2. Metrics (loss, mAP, IoU, etc.)

3. Model artifacts

4. Training plots

5. Git commit information

View experiments at http://127.0.0.1:8080

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å–æ —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö

2. –£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä –ø–∞—Ä—Ç–∏–∏, –µ—Å–ª–∏ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU.

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö

4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è TensorRT –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤
